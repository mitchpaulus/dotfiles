#!/usr/bin/env python3
import sys
import datetime
import mputils
from typing import Optional, Union


class DateParser:
    def __init__(self) -> None:
        self.formats = [
            '%Y-%m-%dT%H:%M:%SZ',
            '%Y-%m-%d %H:%M:%S',
            '%Y-%m-%dT%H:%M:%S%z',
            '%Y-%m-%d %H:%M',
            '%Y-%m-%dT%H:%M',
            '%Y-%m-%dT%H%M',
        ]

        self.current_match = None

    def try_parse(self, date_str: str) -> Optional[datetime.datetime]:
        if self.current_match is not None:
            try:
                return datetime.datetime.strptime(date_str, self.formats[self.current_match]).replace(tzinfo=None)
            except ValueError:
                pass

        for fmt in self.formats:
            try:
                return datetime.datetime.strptime(date_str, fmt).replace(tzinfo=None)
            except ValueError:
                pass
        return None


def no_interpolate(filter_incomplete: bool):
    dates = set()
    data: dict[tuple[str, str], str] = {}

    trends = []
    current_trend = ""
    for line in sys.stdin:
        line = line.strip("\r\n")
        splitline = line.split('\t')

        if len(splitline) == 1:
            current_trend = splitline[0]
            trends.append(current_trend)
        else:
            date = splitline[0]
            value = splitline[1]

            dates.add(date)
            data[(date, current_trend)] = value

    dates = sorted(dates)
    trends = sorted(trends)

    print('Timestamp', end='')
    for trend in trends:
        print('\t' + trend, end='')
    print()

    if filter_incomplete:
        for date in dates:
            if any((date, trend) not in data for trend in trends):
                continue

            print(date, end='')
            for trend in trends:
                print('\t' + data[(date, trend)], end='')
            print()
    else:
        for date in dates:
            print(date, end='')
            for trend in trends:
                if (date, trend) in data:
                    print('\t' + data[(date, trend)], end='')
                else:
                    print('\t', end='')
            print()

def main(filter_incomplete: bool, minute_interval: int, dt: bool):
    date_parser = DateParser()

    min_date = datetime.datetime(9998, 1, 1)
    max_date = datetime.datetime(1, 1, 1)

    all_data: list[tuple[str, list[tuple[datetime.datetime, str]]]] = []

    index = -1

    for line in sys.stdin:
        line = line.strip()
        splitline = line.split('\t')

        if len(splitline) == 1:
            # Search for all_data with the same name
            found = False
            index = 0
            for trend, _ in all_data:
                if trend == splitline[0]:
                    print(f"Found duplicate trend: {splitline[0]}", file=sys.stderr)
                    found = True
                    break
                index += 1

            if not found:
                all_data.append((splitline[0], []))
                index = -1

        else:
            date = date_parser.try_parse(splitline[0])
            if date is None:
                raise Exception(f"Could not parse date: {splitline[0]}")

            all_data[index][1].append((date, splitline[1]))
            if date < min_date:
                min_date = date
            if date > max_date:
                max_date = date

    # Round the min_date down to the nearest interval minutes.
    print(f"Min date: {min_date}, Max date: {max_date}", file=sys.stderr)

    min_date = min_date - datetime.timedelta(minutes=min_date.minute % minute_interval, seconds=min_date.second, microseconds=min_date.microsecond)
    max_date = max_date - datetime.timedelta(minutes=max_date.minute % minute_interval, seconds=max_date.second, microseconds=max_date.microsecond)

    interpolation_dates: list[datetime.datetime] = []
    current_date = min_date
    while current_date <= max_date:
        interpolation_dates.append(current_date)
        current_date += datetime.timedelta(minutes=minute_interval)

    # Interpolate all the data to interval minutes.
    for trend, data in all_data:
        # First sort the data by date.
        data.sort(key=lambda x: x[0])
        interpolate_index_array = mputils.first_index_gteq(interpolation_dates, data, lambda x: x, lambda x: x[0])

        new_data = []

        large_gap_count = 0
        for loop_idx, idx_gte in enumerate(interpolate_index_array):
            if idx_gte is None:
                new_data.append('')
            elif idx_gte == 0 :
                # Check if first value is exactly on boundary.
                date1, value1 = data[idx_gte]
                if date1 == interpolation_dates[loop_idx]:
                    new_data.append(value1)
                else:
                    new_data.append('')
            else:
                # Interpolate the data.
                date1, value1 = data[idx_gte - 1]
                date2, value2 = data[idx_gte]

                # Check difference in times.
                if (date2 - date1).total_seconds() > 3 * minute_interval * 60:
                    large_gap_count += 1
                    new_data.append('')
                    continue

                # Check if both values can be parsed as floats.
                try:
                    float1 = float(value1)
                    float2 = float(value2)
                except ValueError:
                    # Put the previous value.
                    new_data.append(value1)
                    continue

                # Interpolate the value.
                new_value = (float2 - float1) / (date2 - date1).total_seconds() * (interpolation_dates[loop_idx] - date1).total_seconds() + float1

                #  if new_value > 10000:
                    #  print(f'Warning: {trend} has a value of {new_value} at {interpolation_dates[loop_idx]}', file=sys.stderr)
                    #  print(f'float 1: {float1}, float 2: {float2}, date 1: {date1}, date 2: {date2}', file=sys.stderr)

                new_data.append(str(new_value))

        if large_gap_count > 0:
            print(f'Warning: {trend} has {large_gap_count} large gaps', file=sys.stderr)

        # Replace the data with the interpolated data.
        data.clear()
        data.extend(zip(interpolation_dates, new_data))


    mputils.version_sort_by_in_place(all_data, lambda x: x[0])

    # Print as TSV
    if dt:
        # print Header
        print('Timestamp\tYear\tMonth\tDay\tHour\tMinute\tDay Num', end='')
        for trend, _ in all_data:
            print('\t' + trend, end='')
        print()

        for idx_gte, date in enumerate(interpolation_dates):
            if filter_incomplete and any(data[idx_gte][1] == '' for _, data in all_data):
                continue

            date_fields = [
                date.strftime('%Y-%m-%d %H:%M:%S'),
                date.year,
                date.month,
                date.day,
                date.hour,
                date.minute,
                date.weekday(),
            ]

            print("\t".join(map(str, date_fields)), end='')
            for _, data in all_data:
                print('\t' + data[idx_gte][1], end='')
            print()

    else:
        # print Header
        print('Timestamp', end='')
        for trend, _ in all_data:
            print('\t' + trend, end='')
        print()

        for idx_gte, date in enumerate(interpolation_dates):
            if filter_incomplete and any(data[idx_gte][1] == '' for _, data in all_data):
                continue

            print(date.strftime('%Y-%m-%d %H:%M:%S'), end='')
            for _, data in all_data:
                print('\t' + data[idx_gte][1], end='')
            print()

# Define tokens
filter_incomplete_token = 1
interval_token = 2
string_token = 3
integer_token = 4
help_token = 5
no_interpolate_token = 6
dt_token = 7
eof = 8

class Token:
    def __init__(self, token_type: int, value: str):
        self.token_type = token_type
        self.value = value

    def __str__(self):
        return f"Token({self.token_type}, {self.value})"

class CliLexer:
    def __init__(self, args: list[str]):
        self.args = args
        self.idx = 0
        self.current_token = self.consume()

    def consume(self) -> Token:
        self.idx += 1
        if self.idx >= len(self.args):
            return Token(eof, '')

        str_val = self.args[self.idx]
        if str_val == "--filter-incomplete":
            return Token(filter_incomplete_token, str_val)
        elif str_val == "--interval" or str_val == "-i":
            return Token(interval_token, str_val)
        elif str_val == "-h" or str_val == "--help":
            return Token(help_token, str_val)
        elif str_val == "--no-interpolate":
            return Token(no_interpolate_token, str_val)
        elif str_val == "--dt":
            return Token(dt_token, str_val)
        elif str_val.startswith('-'):
            raise Exception(f"Unknown option {str_val}")
        # Else if try parse as integer
        elif str_val.isdigit():
            return Token(integer_token, str_val)
        else:
            return Token(string_token, str_val)

    def peek(self) -> Token:
        return self.current_token

class CliParser:
    lookahead: Token

    def __init__(self, lex: CliLexer):
        self.lex = lex
        self.lookahead = lex.peek()
        self.options = Options()

    def match(self, expected: int) -> Token:
        if self.lookahead.token_type == expected:
            current = self.lookahead
            self.lookahead = self.lex.consume()
            return current
        else:
            raise Exception(f"Expected {expected}, got {self.lookahead}")

    def parse_interval_option(self):
        self.match(interval_token)
        self.options.interval = int(self.match(integer_token).value)

    def parse_options(self):
        while True:
            # print(self.lookahead, file=sys.stderr)
            if self.lookahead.token_type == eof:
                break

            if self.lookahead.token_type == filter_incomplete_token:
                self.match(filter_incomplete_token)
                self.options.filter_incomplete = True
            elif self.lookahead.token_type == interval_token:
                self.parse_interval_option()
            elif self.lookahead.token_type == no_interpolate_token:
                self.options.no_interpolate = True
                self.match(no_interpolate_token)
            elif self.lookahead.token_type == help_token:
                print("Usage: mp2tsv OPTIONS < FILE")
                print("Options:")
                print("  --filter-incomplete: Filter out incomplete data, any row that is not totally complete will be removed.")
                print("  --interval, -i: Set the interval in minutes for the output data. Default is 5 minutes.")
                print("  --no-interpolate: Do not interpolate data.")
                sys.exit(0)
            elif self.lookahead.token_type == dt_token:
                self.options.dt = True
                self.match(dt_token)
            else:
                raise Exception(f"Unexpected token {self.lookahead}")

        return

    def parse(self):
        self.parse_options()
        return self.options


class Options:
    def __init__(self):
        self.filter_incomplete = False
        self.interval = 5
        self.no_interpolate = False
        self.dt = False

    def __str__(self):
        return f"Filter incomplete: {self.filter_incomplete}, Interval: {self.interval}, No interpolate: {self.no_interpolate}"

    def __repr__(self):
        return str(self)

if __name__ == "__main__":
    lex = CliLexer(sys.argv)
    parser = CliParser(lex)

    options = parser.parse()

    print(options, file=sys.stderr)

    if options.no_interpolate:
        no_interpolate(options.filter_incomplete)
    else:
        main(options.filter_incomplete, options.interval, options.dt)
